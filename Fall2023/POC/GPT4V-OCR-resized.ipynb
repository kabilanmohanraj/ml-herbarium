{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT4 Vision OCR implementation - Smriti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify the existing prompt to GPT4-V to conform the results to the Darwin Core standard that is typical for biodiversity specimen information. We plan on utilizing Scientific Name, Locality/Country and Collector Name for the evaluation of the labels we obtain from the LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./lib/python3.10/site-packages (1.1.2)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in ./lib/python3.10/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in ./lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./lib/python3.10/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./lib/python3.10/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./lib/python3.10/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: tqdm>4 in ./lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: exceptiongroup in ./lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./lib/python3.10/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore in ./lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
      "Requirement already satisfied: certifi in ./lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in ./lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./lib/python3.10/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the API we make requests to the newly released GPT4-V model to transcribe the text from the TROCR Evaluation set data and save the responses in a json format in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projectnb/sparkgrp/ml-herbarium-grp/fall2023\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# os.chdir(\"ml-herbarium-grp\")\n",
    "print(os.getcwd())\n",
    "json_results = defaultdict()\n",
    "too_big = []\n",
    "# OpenAI API Key\n",
    "api_key = key\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "# folder_path = \"ml-herbarium-data/TROCR_Training/goodfiles/\"\n",
    "folder_path = \"resized-images/\"\n",
    "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and f.endswith(('jpg', 'png'))]\n",
    "\n",
    "for img in image_files:\n",
    "    if os.stat(img).st_size > 19000000:\n",
    "        too_big.append(img)\n",
    "    else:\n",
    "    # Getting the base64 string\n",
    "        base64_image = encode_image(img)\n",
    "        \n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {api_key}\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": \"gpt-4-vision-preview\",\n",
    "            \"messages\": [\n",
    "              {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                  {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Extract all the text, both typed and handwritten from this image and display it in a JSON format according to the Darwin Core standard for biodiversity specimen\"\n",
    "                  },\n",
    "                  {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                      \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                  }\n",
    "                ]\n",
    "              }\n",
    "            ],\n",
    "            \"max_tokens\": 4096\n",
    "        }\n",
    "    \n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        json_results[img] = response.json()\n",
    "    \n",
    "    # print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note : We observed that the image file size by Azure and GPT4-V were limited to 20MB and so we resized the images to size under 4MB for easier processing by the APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['resized-images/1320398138.jpg', 'resized-images/1802552799.jpg', 'resized-images/1998322454.jpg', 'resized-images/2236142683.jpg', 'resized-images/2848499425.jpg', 'resized-images/2446828826.jpg', 'resized-images/2284257102.jpg', 'resized-images/2608680770.jpg', 'resized-images/2595747531.jpg', 'resized-images/3356834058.jpg', 'resized-images/2859042459.jpg', 'resized-images/3005750161.jpg', 'resized-images/1320488541.jpg', 'resized-images/1998358368.jpg', 'resized-images/1998413329.jpg', 'resized-images/1322099762.jpg', 'resized-images/1998836464.jpg', 'resized-images/2549603947.jpg', 'resized-images/1675940934.jpg', 'resized-images/1998540182.jpg', 'resized-images/1990825865.jpg', 'resized-images/2236176339.jpg', 'resized-images/1999330570.jpg', 'resized-images/3356803607.jpg', 'resized-images/2512789170.jpg', 'resized-images/1998481102.jpg', 'resized-images/2425404585.jpg', 'resized-images/3092906623.jpg', 'resized-images/2512801142.jpg', 'resized-images/2265485412.jpg', 'resized-images/2426921679.jpg', 'resized-images/1998394637.jpg', 'resized-images/2573054178.jpg', 'resized-images/2235755905.jpg', 'resized-images/3341257544.jpg', 'resized-images/2234232983.jpg', 'resized-images/2900445104.jpg', 'resized-images/1455960532.jpg', 'resized-images/1990824315.jpg', 'resized-images/3005755518.jpg', 'resized-images/1999401722.jpg', 'resized-images/2452246731.jpg', 'resized-images/1317278320.jpg', 'resized-images/1320104750.jpg', 'resized-images/2236024256.jpg', 'resized-images/1998370401.jpg', 'resized-images/2452236904.jpg', 'resized-images/2284153322.jpg', 'resized-images/1317726996.jpg', 'resized-images/1999314245.jpg', 'resized-images/1929881359.jpg', 'resized-images/1563240212.jpg', 'resized-images/1998550976.jpg', 'resized-images/2512761763.jpg', 'resized-images/3459889344.jpg', 'resized-images/2625898343.jpg', 'resized-images/1999130856.jpg', 'resized-images/1998465329.jpg', 'resized-images/1930277693.jpg', 'resized-images/1999143240.jpg', 'resized-images/2446828060.jpg', 'resized-images/3341248414.jpg', 'resized-images/1998387245.jpg', 'resized-images/2900461439.jpg', 'resized-images/2236147388.jpg', 'resized-images/1928370989.jpg', 'resized-images/1998729261.jpg', 'resized-images/3356836015.jpg', 'resized-images/2848506530.jpg', 'resized-images/2571435846.jpg', 'resized-images/1998818359.jpg', 'resized-images/2643351883.jpg', 'resized-images/3467354375.jpg', 'resized-images/1802596511.jpg', 'resized-images/3005774322.jpg', 'resized-images/2236156450.jpg', 'resized-images/2608673843.jpg', 'resized-images/1998980522.jpg', 'resized-images/1563299852.jpg', 'resized-images/1318212360.jpg', 'resized-images/1929709919.jpg', 'resized-images/2900455868.jpg', 'resized-images/1931124118.jpg', 'resized-images/1426166249.jpg', 'resized-images/1455174725.jpg', 'resized-images/3111515383.jpg', 'resized-images/2426886454.jpg', 'resized-images/2512804326.jpg', 'resized-images/2425445076.jpg', 'resized-images/2426902656.jpg', 'resized-images/2643353998.jpg', 'resized-images/2235866543.jpg', 'resized-images/2426917844.jpg', 'resized-images/1998882868.jpg', 'resized-images/1319210580.jpg', 'resized-images/2235995189.jpg', 'resized-images/1998590947.jpg', 'resized-images/2284193310.jpg', 'resized-images/1322253698.jpg', 'resized-images/2452262576.jpg', 'resized-images/1998565761.jpg', 'resized-images/2565452643.jpg', 'resized-images/2575053354.jpg', 'resized-images/1998497875.jpg', 'resized-images/2235847388.jpg', 'resized-images/2452230713.jpg', 'resized-images/2284154890.jpg', 'resized-images/2236018163.jpg', 'resized-images/2575086103.jpg', 'resized-images/1702827727.jpg', 'resized-images/1318334082.jpg', 'resized-images/437160969.jpg', 'resized-images/2575039168.jpg', 'resized-images/1999032409.jpg', 'resized-images/1456008930.jpg', 'resized-images/2284326054.jpg', 'resized-images/2236597761.jpg', 'resized-images/2595756978.jpg', 'resized-images/1998543749.jpg', 'resized-images/1317746297.jpg', 'resized-images/3357284466.jpg', 'resized-images/1456250583.jpg', 'resized-images/1999154508.jpg', 'resized-images/1998758107.jpg', 'resized-images/1322958063.jpg', 'resized-images/2284150251.jpg', 'resized-images/2236057326.jpg', 'resized-images/2625904355.jpg', 'resized-images/1998333126.jpg', 'resized-images/1999413720.jpg', 'resized-images/1426171668.jpg', 'resized-images/1318393575.jpg', 'resized-images/1317840733.jpg', 'resized-images/1998686142.jpg', 'resized-images/1998308840.jpg', 'resized-images/1852143901.jpg', 'resized-images/3043554903.jpg', 'resized-images/2265509546.jpg', 'resized-images/1999283271.jpg', 'resized-images/1999056693.jpg', 'resized-images/1998968996.jpg', 'resized-images/2549483800.jpg', 'resized-images/1999317509.jpg', 'resized-images/2446819762.jpg', 'resized-images/1321992876.jpg', 'resized-images/2592238071.jpg', 'resized-images/2858981761.jpg', 'resized-images/3341239321.jpg', 'resized-images/2425414867.jpg', 'resized-images/1998956483.jpg', 'resized-images/2265566552.jpg', 'resized-images/2859305213.jpg', 'resized-images/2549491705.jpg', 'resized-images/2512820352.jpg', 'resized-images/1320460457.jpg', 'resized-images/2284189808.jpg', 'resized-images/2012884607.jpg', 'resized-images/1999410499.jpg', 'resized-images/1318373170.jpg', 'resized-images/1998543588.jpg', 'resized-images/2452293722.jpg', 'resized-images/1928034398.jpg', 'resized-images/1318526260.jpg', 'resized-images/1999217275.jpg', 'resized-images/1998611243.jpg', 'resized-images/2549492260.jpg', 'resized-images/1928479020.jpg', 'resized-images/2235846679.jpg', 'resized-images/2284285249.jpg', 'resized-images/1999110359.jpg', 'resized-images/2425435971.jpg', 'resized-images/2625852862.jpg', 'resized-images/1998808952.jpg', 'resized-images/2512759946.jpg', 'resized-images/2265588715.jpg', 'resized-images/1998994775.jpg', 'resized-images/2235813242.jpg', 'resized-images/2848440467.jpg', 'resized-images/2859014941.jpg', 'resized-images/3385632342.jpg', 'resized-images/2848503382.jpg', 'resized-images/1998969928.jpg', 'resized-images/2571504032.jpg', 'resized-images/1318797445.jpg', 'resized-images/1702851818.jpg', 'resized-images/3092956655.jpg', 'resized-images/1146138679.jpg', 'resized-images/1999167579.jpg', 'resized-images/1998467065.jpg', 'resized-images/2236116492.jpg', 'resized-images/2625876902.jpg', 'resized-images/1929883118.jpg', 'resized-images/2859205685.jpg', 'resized-images/2549496787.jpg', 'resized-images/2284359495.jpg', 'resized-images/1318345053.jpg', 'resized-images/1318027385.jpg', 'resized-images/3703056529.jpg', 'resized-images/1321746477.jpg', 'resized-images/2397779786.jpg', 'resized-images/1676047656.jpg', 'resized-images/2452332496.jpg', 'resized-images/1852124166.jpg', 'resized-images/2397724211.jpg', 'resized-images/1998482052.jpg', 'resized-images/1318293083.jpg', 'resized-images/2397721138.jpg', 'resized-images/1456276626.jpg', 'resized-images/1998646322.jpg', 'resized-images/2236950433.jpg', 'resized-images/3005670412.jpg', 'resized-images/1456376042.jpg', 'resized-images/1998387136.jpg', 'resized-images/2900436116.jpg', 'resized-images/1999047345.jpg', 'resized-images/1212567865.jpg', 'resized-images/2235956175.jpg', 'resized-images/2565407235.jpg', 'resized-images/1426052966.jpg', 'resized-images/1998843424.jpg', 'resized-images/1843567618.jpg', 'resized-images/1928246346.jpg', 'resized-images/3005768358.jpg', 'resized-images/1930449245.jpg', 'resized-images/2625851024.jpg', 'resized-images/1927799942.jpg', 'resized-images/2425437928.jpg', 'resized-images/2235965636.jpg', 'resized-images/1999105588.jpg', 'resized-images/1146376618.jpg', 'resized-images/2592277723.jpg', 'resized-images/1322630109.jpg', 'resized-images/3734813368.jpg', 'resized-images/1999028044.jpg', 'resized-images/2512764119.jpg', 'resized-images/1318182025.jpg', 'resized-images/1999262308.jpg', 'resized-images/3392122454.jpg', 'resized-images/1990809725.jpg', 'resized-images/1319326174.jpg', 'resized-images/2236031445.jpg', 'resized-images/2512855384.jpg', 'resized-images/1999253468.jpg', 'resized-images/2397800089.jpg', 'resized-images/2012879889.jpg', 'resized-images/1928276301.jpg', 'resized-images/2235750047.jpg', 'resized-images/1929084979.jpg', 'resized-images/1319864119.jpg', 'resized-images/2625873744.jpg', 'resized-images/3005727173.jpg'])\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "copyjson = json_results.copy()\n",
    "print(json_results.keys())\n",
    "for l in list(json_results.keys()):\n",
    "    if \"choices\" not in json_results[cl].keys():\n",
    "        del json_results[l]\n",
    "    else:\n",
    "        json_results[l] = json_results[l]['choices'][0]['message']['content']\n",
    "\n",
    "print(len(json_results))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'resized-images/1320398138.jpg': 'To display the extracted text in a JSON format according to the Darwin Core standard for biodiversity specimen records, the following fields have been identified and organized:\\n\\n```json\\n{\\n  \"institutionCode\": \"US\",\\n  \"collectionCode\": \"Botany\",\\n  \"catalogNumber\": \"1622390\",\\n  \"scientificName\": \"Monopyle maxima Morton\",\\n  \"typeStatus\": \"Holotype\",\\n  \"recordedBy\": \"Ynes Mexia\",\\n  \"recordNumber\": \"7017\",\\n  \"country\": \"Ecuador\",\\n  \"stateProvince\": \"Zamora\",\\n  \"locality\": \"Beyond Estacion Zamora\",\\n  \"habitat\": \"Cloud forest\",\\n  \"dateIdentified\": \"1945\",\\n  \"eventDate\": \"22-26, 1935\",\\n  \"decimalLatitude\": \"\",\\n  \"decimalLongitude\": \"\",\\n  \"minimumElevationInMeters\": \"500\",\\n  \"maximumElevationInMeters\": \"900\",\\n  \"verbatimElevation\": \"altitude 500-900 meters\",\\n  \"occurrenceRemarks\": \"(Tree cover!)\"\\n}\\n```\\n\\nPlease note that some standard Darwin Core fields such as `decimalLatitude` and `decimalLongitude` cannot be provided because this information is not available in the image. Additionally, the verbatim label information has been interpreted to fill DwC fields as appropriately as possible, but some information such as exact geographic coordinates or precise `eventDate` formatting is not provided from the label and thus is left empty.\\n\\nAlso, it is important to acknowledge that some fields in the Darwin Core standard such as `eventDate` are best formatted in a specific way (e.g., ISO 8601 dates), but since the image provides the dates as \"22-26, 1935\", it has been left as is for accuracy.'})\n"
     ]
    }
   ],
   "source": [
    "print(json_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(too_big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "paths = list(json_results.keys())\n",
    "# folder_path = \"ml-herbarium-data/TROCR_Training/goodfiles/\"\n",
    "folder_path = \"resized-images/\"\n",
    "img_names = [i.replace(folder_path, \"\") for i in paths]\n",
    "\n",
    "# print(img_names)\n",
    "final_dict = defaultdict()\n",
    "\n",
    "for img in img_names:\n",
    "    final_dict[img] = json_results[folder_path+img]\n",
    "\n",
    "print(len(final_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'message': {'role': 'assistant', 'content': '```json\\n{\\n  \"Image Number\": \"00427028\",\\n  \"Specimen ID\": \"1627083\",\\n  \"Herbarium\": \"UNITED STATES NATIONAL MUSEUM\",\\n  \"Flora\": \"Flora Hawaiiensis\",\\n  \"Collected by\": \"C. N. Forbes on Oahu\",\\n  \"Species Name\": \"Cheirodendron platyphyllum (Hook. & Arn.) Frodin\",\\n  \"Collection Date\": \"Apr. 26 - May 6 - 1911\",\\n  \"Accession Number\": \"No. 74318\",\\n  \"Barcode of the Bishop Museum Herbarium\": \"Image No. 00427028\"\\n}\\n```'}, 'finish_details': {'type': 'stop', 'stop': '<|fim_suffix|>'}, 'index': 0}]\n"
     ]
    }
   ],
   "source": [
    "#TEST CODE\n",
    "# lists = list(json_results.values())\n",
    "# print(lists[0]['choices'])\n",
    "# contents = [l['choices'][0]['message']['content'] for l in lists]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "# print(len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Herbarium Label\": {\n",
      "    \"Scientific Name\": \"Cheirodendron trigynum (Gaud.) A. Heller var. helleri Sherff\",\n",
      "    \"Collection Information\": \"Flora Hawaiianensis. Collected by C. N. Forbes on Oahu.\",\n",
      "    \"Location\": \"Punaluu, Koolau Mts.\",\n",
      "    \"Elevation\": \"Apl. 1-20\" + \"May 6 - 1914\",\n",
      "    \"Collector Number\": \"XV: 5/18\",\n",
      "    \"Barcode\": \"00427028\"\n",
      "  },\n",
      "  \"Institution Label\": {\n",
      "    \"Institution\": \"UNITED STATES NATIONAL MUSEUM\",\n",
      "    \"Specimen Number\": \"1627083\"\n",
      "  },\n",
      "  \"Imaging Label\": {\n",
      "    \"Image Number\": \"Image No. 00427028\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "Please note that there could be slight inaccuracies in transcription due to the handwriting and the quality of the image. The elevation appears to be a range given with a mixture of dates (April 1-20, May 6, 1914) which is transcribed as given.\n"
     ]
    }
   ],
   "source": [
    "# print(contents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We save the contents of each image in the form of txt files since there are also comments from the model regarding most of the transcriptions that could be useful while evaluating results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projectnb/sparkgrp/ml-herbarium-grp/fall2023\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "for i in final_dict:\n",
    "    f = open(\"gpt4v-resized-results/\"+i.replace(\"jpg\", \"txt\"), \"w\")\n",
    "    f.writelines(final_dict[i])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation from the results : \n",
    "\n",
    "**TROCR Evaluation set** : Images were resized and we were able to get results for all 250 evaluation set images, according to the Darwin Core format the client requested. We are working on the evaluation metrics now to compare the ground truth labels with the LLM generated ones. We plan on pushing evaluation code by this week. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
