{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836a1e2e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46338c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and installs\n",
    "import transformers\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from craft_text_detector import Craft # Need to edit the saving function to prepend 0's\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "\n",
    "import trocr\n",
    "\n",
    "from taxonerd import TaxoNERD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeef3de",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e2538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppressing all the huggingface warnings\n",
    "SUPPRESS = True\n",
    "if SUPPRESS:\n",
    "    from transformers.utils import logging\n",
    "    logging.set_verbosity(40)\n",
    "# Turning off this warning, isn't relevant for this application\n",
    "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)\n",
    "\n",
    "# Location of images\n",
    "workdir = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/TROCR_Training/goodfiles/' # update this to the desired directory on scc\n",
    "# Location of the segmentations\n",
    "output_dir_craft = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/craft_output_files_no_detr/'\n",
    "# Location to save all output files\n",
    "save_dir = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data-spring2023/saved_results_trocr/'\n",
    "# For ground truth labels \n",
    "workdir2 = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/scraped-data/drago_testdata/gt_labels' # update this to the desired directory on scc\n",
    "\n",
    "# Corpus files\n",
    "ALL_SPECIES_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_species.pkl'\n",
    "ALL_GENUS_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-data/corpus_taxon/output/possible_genus.pkl'\n",
    "ALL_TAXON_FILE = '/projectnb/sparkgrp/ml-herbarium-grp/ml-herbarium-new/ml-herbarium/corpus/corpus_taxon/corpus_taxon.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99c22b",
   "metadata": {},
   "source": [
    "# Running craft and saving the segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b3457a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [10:35<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "# initialize the CRAFT model\n",
    "craft = Craft(output_dir = output_dir_craft, \n",
    "              export_extra = False, \n",
    "              text_threshold = .7, \n",
    "              link_threshold = .4, \n",
    "              crop_type=\"poly\", \n",
    "              low_text = .3, \n",
    "              cuda = True)\n",
    "\n",
    "# CRAFT on images to get bounding boxes\n",
    "images = []\n",
    "corrupted_images = []\n",
    "no_segmentations = []\n",
    "boxes = {}\n",
    "count= 0\n",
    "img_name = []\n",
    "box = []\n",
    "file_types = (\".jpg\", \".jpeg\",\".png\")\n",
    "    \n",
    "for filename in tqdm(sorted(os.listdir(workdir))):\n",
    "    if filename.endswith(file_types):\n",
    "        image = workdir+filename\n",
    "        try:\n",
    "            img = Image.open(image) \n",
    "            img.verify() # Check that the image is valid\n",
    "            bounding_areas = craft.detect_text(image)\n",
    "            if len(bounding_areas['boxes']): #check that a segmentation was found\n",
    "                images.append(image)\n",
    "                boxes[image] = bounding_areas['boxes']\n",
    "                \n",
    "            else:\n",
    "                no_segmentations.append(image)\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            corrupted_images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d255c2b3",
   "metadata": {},
   "source": [
    "# Getting all the segmented images into a dataloader, and loading model and processor for trocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf2b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting empty folders, which occurs if some of the images get no segementation from CRAFT\n",
    "root = output_dir_craft\n",
    "folders = list(os.walk(root))[1:]\n",
    "deleted = []\n",
    "for folder in folders:\n",
    "    if not folder[2]:\n",
    "        deleted.append(folder)\n",
    "        os.rmdir(folder[0])\n",
    "        \n",
    "# Setting up the Tr-OCR model and processor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\") \n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\").to(device)\n",
    "\n",
    "# Use all available gpus\n",
    "model_gpu= nn.DataParallel(model,list(range(torch.cuda.device_count()))).to(device)\n",
    "\n",
    "# Dataloader for working with gpus\n",
    "trainset = datasets.ImageFolder(output_dir_craft, transform = processor)\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=False)\n",
    "\n",
    "# For matching words to image\n",
    "filenames = [s.replace('_crops', '') for s in list(trainset.class_to_idx)]\n",
    "\n",
    "# For matching the image name with the label name\n",
    "word_log_dic = {k: v for k,v in enumerate(filenames)}\n",
    "# For matching the image name with the transriptions\n",
    "words_identified = {k: [] for v,k in enumerate(filenames)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17dc11",
   "metadata": {},
   "source": [
    "# Saving the filenames, word_log_dic and words_identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dcb988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filenames\n",
    "with open(save_dir+'filenames.txt', 'w') as fp:\n",
    "    for item in filenames:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "# Save word_log_dic \n",
    "with open(save_dir+'word_log_dic.json', 'w') as fp:\n",
    "    json.dump(word_log_dic, fp)\n",
    "# Save words_identified\n",
    "with open(save_dir+'words_identified.json', 'w') as fp:\n",
    "    json.dump(words_identified, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b47fc7",
   "metadata": {},
   "source": [
    "# Running Tr-OCR on the Segmented Images from Craft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "952d659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing Image Segments:   0%|          | 0/341 [00:00<?, ?it/s]/projectnb/sparkgrp/kabilanm/.conda/envs/trocr_env/lib/python3.9/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Transcribing Image Segments: 100%|██████████| 341/341 [05:08<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "#Storing the outputs\n",
    "results,confidence,labels = trocr.evaluate_craft_seg(model,processor, words_identified,word_log_dic,testloader,device)\n",
    "#Saving all the outputs in dataframe\n",
    "df = pd.DataFrame(list(zip(results,confidence,labels)),columns = ['Results','Confidence','Labels'])\n",
    "df.to_pickle(save_dir+'full_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6def9a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_Confidence</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Bounding_Boxes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Museum d'Histoire naturelle de Paris, Herbier...</td>\n",
       "      <td>[0.2456074208021164, 0.5142542719841003, 0.997...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[3858.9062, 280.7068], [5929.0693, 357.37952...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[100s, 100p, 0, 100p., 2nd, 100,, top, 100, 10...</td>\n",
       "      <td>[0.005754438694566488, 0.0021388500463217497, ...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[6485.1157, 425.71875], [6612.831, 425.71875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0-, 100,, ed state., 1627083, United States n...</td>\n",
       "      <td>[0.02574569173157215, 0.04106131196022034, 0.3...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[6399.1187, 307.38126], [6524.8657, 307.3812...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[us, 8.810, own, copyright reserved, 1685951, ...</td>\n",
       "      <td>[0.07571566849946976, 0.05967206507921219, 0.0...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[3286.3594, 168.53125], [3539.1562, 168.5312...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, flora of the, Washington Baltimore area,...</td>\n",
       "      <td>[0.021984726190567017, 0.11620793491601944, 0....</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[6408.428, 710.46875], [6536.3125, 710.46875...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                      Transcription  \\\n",
       "0       0  [Museum d'Histoire naturelle de Paris, Herbier...   \n",
       "1       1  [100s, 100p, 0, 100p., 2nd, 100,, top, 100, 10...   \n",
       "2       2  [0-, 100,, ed state., 1627083, United States n...   \n",
       "3       3  [us, 8.810, own, copyright reserved, 1685951, ...   \n",
       "4       4  [100, flora of the, Washington Baltimore area,...   \n",
       "\n",
       "                            Transcription_Confidence  \\\n",
       "0  [0.2456074208021164, 0.5142542719841003, 0.997...   \n",
       "1  [0.005754438694566488, 0.0021388500463217497, ...   \n",
       "2  [0.02574569173157215, 0.04106131196022034, 0.3...   \n",
       "3  [0.07571566849946976, 0.05967206507921219, 0.0...   \n",
       "4  [0.021984726190567017, 0.11620793491601944, 0....   \n",
       "\n",
       "                                          Image_Path  \\\n",
       "0  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "1  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "2  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "3  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "4  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "\n",
       "                                      Bounding_Boxes  \n",
       "0  [[[3858.9062, 280.7068], [5929.0693, 357.37952...  \n",
       "1  [[[6485.1157, 425.71875], [6612.831, 425.71875...  \n",
       "2  [[[6399.1187, 307.38126], [6524.8657, 307.3812...  \n",
       "3  [[[3286.3594, 168.53125], [3539.1562, 168.5312...  \n",
       "4  [[[6408.428, 710.46875], [6536.3125, 710.46875...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First part of final csv with results, confidence level from tr-ocr, and label\n",
    "combined_df = trocr.combine_by_label(df)\n",
    "\n",
    "# Adding the image path and all bounding boxes \n",
    "\n",
    "df_dictionary = pd.DataFrame(boxes.items(), columns=['Image_Path', 'Bounding_Boxes'])\n",
    "combined_df = pd.concat([combined_df, df_dictionary], axis=1, join='inner')\n",
    "display(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f663f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save intermediate file\n",
    "combined_df.to_pickle(save_dir+'/test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3e4c9",
   "metadata": {},
   "source": [
    "# Reading in the ground truth files for tested images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f74ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the ground truth values\n",
    "\n",
    "gt_t = workdir2+'/taxon_gt.txt'\n",
    "Taxon_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_t) }\n",
    "\n",
    "gt_g = workdir2+'/geography_gt.txt'\n",
    "Geography_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_g) }\n",
    "\n",
    "gt_c = workdir2+'/collector_gt.txt'\n",
    "Collector_truth = { line.split(\":\")[0] : line.split(\": \")[1].strip() for line in open(gt_c) }\n",
    "\n",
    "comparison_file = {\"Taxon\":Taxon_truth,\"Countries\":Geography_truth,\"Collector\":Collector_truth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89201644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1697659851': 'Euphrasia officinalis', '2573258025': 'Bryoerythrophyllum recurvirostrum', '2597666444': 'Carduus tenuiflorus', '1931288980': 'Agoseris parviflora', '1930241969': 'Spiraea canescens', '1929944910': 'Chylismia scapoidea', '1931007576': 'Carex typhina', '1928514234': 'Stachys hispida', '1928658806': 'Solanum donianum', '1931124118': 'Suaeda nigra'}\n"
     ]
    }
   ],
   "source": [
    "Taxon_truth_sample = {k: Taxon_truth[k] for k in list(Taxon_truth)[:10]}\n",
    "\n",
    "# view subset of the taxon truth\n",
    "print(Taxon_truth_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb09b32",
   "metadata": {},
   "source": [
    "# Use TaxoNERD to recognize taxons from detected text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2ec299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 18 10:29:51 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   60C    P0              50W / 250W |   4070MiB / 16384MiB |      5%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE-16GB           On  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              24W / 250W |      0MiB / 16384MiB |      0%   E. Process |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1190742      C   ...nm/.conda/envs/trocr_env/bin/python     4066MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3d68180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Jun_13_19:16:58_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.91\n",
      "Build cuda_12.2.r12.2/compiler.32965470_0\n"
     ]
    }
   ],
   "source": [
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b0c983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonerd = TaxoNERD(prefer_gpu=False) # set to \"true\" if GPU is accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3ee7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for finding cosine similarity\n",
    "\n",
    "def word2vec(word):\n",
    "    from collections import Counter\n",
    "    from math import sqrt\n",
    "\n",
    "    # count the characters in word\n",
    "    cw = Counter(word)\n",
    "    # precomputes a set of the different characters\n",
    "    sw = set(cw)\n",
    "    # precomputes the \"length\" of the word vector\n",
    "    lw = sqrt(sum(c*c for c in cw.values()))\n",
    "\n",
    "    # return a tuple\n",
    "    return cw, sw, lw\n",
    "\n",
    "def cosdis(v1, v2):\n",
    "    # which characters are common to the two words?\n",
    "    common = v1[1].intersection(v2[1])\n",
    "    # by definition of cosine distance we have\n",
    "    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccdd1ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projectnb/sparkgrp/ml-herbarium-grp/summer2023/kabilanm/ml-herbarium/trocr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n"
     ]
    }
   ],
   "source": [
    "# test \"gbif_backbone\" linker -> more species here\n",
    "# use BERT for person and location information\n",
    "\n",
    "taxon_output = []\n",
    "confidence_output = []\n",
    "\n",
    "nlp = taxonerd.load(\n",
    "    model=\"en_core_eco_biobert\", \n",
    "    linker=\"gbif_backbone\", \n",
    "    threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88e0f116",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [09:30<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# predict taxons for text detected from each image\n",
    "for index, row in tqdm(combined_df.iterrows(), total=combined_df.shape[0]):\n",
    "    temp = row[\"Transcription\"]\n",
    "\n",
    "    # construct a single string out of all the detected text\n",
    "    input_text = \" \".join(temp) \n",
    "    doc = taxonerd.find_in_text(input_text)\n",
    "\n",
    "    try:\n",
    "        # append linked taxon entity and confidence\n",
    "        taxon_output.append(str(doc.entity[0][0][1]))\n",
    "        confidence_output.append(float(doc.entity[0][0][2]))\n",
    "\n",
    "    except AttributeError:\n",
    "        # append empty strings when no entity is detected\n",
    "        taxon_output.append(\"\")\n",
    "        confidence_output.append(float(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d947b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append predicted taxon and confidence scores to the dataframe\n",
    "combined_df[\"Taxon_Output\"] = taxon_output\n",
    "combined_df[\"Confidence_Output\"] = confidence_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9641e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_Confidence</th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Bounding_Boxes</th>\n",
       "      <th>Taxon_Output</th>\n",
       "      <th>Confidence_Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Museum d'Histoire naturelle de Paris, Herbier...</td>\n",
       "      <td>[0.2456074208021164, 0.5142542719841003, 0.997...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[3858.9062, 280.7068], [5929.0693, 357.37952...</td>\n",
       "      <td>Ferraria pavonia</td>\n",
       "      <td>0.909291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[100s, 100p, 0, 100p., 2nd, 100,, top, 100, 10...</td>\n",
       "      <td>[0.005754438694566488, 0.0021388500463217497, ...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[6485.1157, 425.71875], [6612.831, 425.71875...</td>\n",
       "      <td>Iduliella</td>\n",
       "      <td>0.415965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0-, 100,, ed state., 1627083, United States n...</td>\n",
       "      <td>[0.02574569173157215, 0.04106131196022034, 0.3...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[6399.1187, 307.38126], [6524.8657, 307.3812...</td>\n",
       "      <td>Clermontia persicifolia</td>\n",
       "      <td>0.593744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[us, 8.810, own, copyright reserved, 1685951, ...</td>\n",
       "      <td>[0.07571566849946976, 0.05967206507921219, 0.0...</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[3286.3594, 168.53125], [3539.1562, 168.5312...</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[100, flora of the, Washington Baltimore area,...</td>\n",
       "      <td>[0.021984726190567017, 0.11620793491601944, 0....</td>\n",
       "      <td>/projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...</td>\n",
       "      <td>[[[6408.428, 710.46875], [6536.3125, 710.46875...</td>\n",
       "      <td>Elymus hystrix L.</td>\n",
       "      <td>0.791353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Labels                                      Transcription  \\\n",
       "0       0  [Museum d'Histoire naturelle de Paris, Herbier...   \n",
       "1       1  [100s, 100p, 0, 100p., 2nd, 100,, top, 100, 10...   \n",
       "2       2  [0-, 100,, ed state., 1627083, United States n...   \n",
       "3       3  [us, 8.810, own, copyright reserved, 1685951, ...   \n",
       "4       4  [100, flora of the, Washington Baltimore area,...   \n",
       "\n",
       "                            Transcription_Confidence  \\\n",
       "0  [0.2456074208021164, 0.5142542719841003, 0.997...   \n",
       "1  [0.005754438694566488, 0.0021388500463217497, ...   \n",
       "2  [0.02574569173157215, 0.04106131196022034, 0.3...   \n",
       "3  [0.07571566849946976, 0.05967206507921219, 0.0...   \n",
       "4  [0.021984726190567017, 0.11620793491601944, 0....   \n",
       "\n",
       "                                          Image_Path  \\\n",
       "0  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "1  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "2  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "3  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "4  /projectnb/sparkgrp/ml-herbarium-grp/ml-herbar...   \n",
       "\n",
       "                                      Bounding_Boxes             Taxon_Output  \\\n",
       "0  [[[3858.9062, 280.7068], [5929.0693, 357.37952...         Ferraria pavonia   \n",
       "1  [[[6485.1157, 425.71875], [6612.831, 425.71875...                Iduliella   \n",
       "2  [[[6399.1187, 307.38126], [6524.8657, 307.3812...  Clermontia persicifolia   \n",
       "3  [[[3286.3594, 168.53125], [3539.1562, 168.5312...                            \n",
       "4  [[[6408.428, 710.46875], [6536.3125, 710.46875...        Elymus hystrix L.   \n",
       "\n",
       "   Confidence_Output  \n",
       "0           0.909291  \n",
       "1           0.415965  \n",
       "2           0.593744  \n",
       "3           0.000000  \n",
       "4           0.791353  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6769c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array to store computed similarity scores\n",
    "cosine_sim = []\n",
    "\n",
    "for index, row in combined_df.iterrows():\n",
    "\n",
    "    # extract image name from the dataframe\n",
    "    img_name = row[\"Image_Path\"].split(\"/\")[-1][:-4]\n",
    "    taxon_predicted = row[\"Taxon_Output\"]\n",
    "    taxon_gt = Taxon_truth[img_name]\n",
    "\n",
    "    # compute cosine similarity between the predicted taxon and ground truth\n",
    "    try:\n",
    "        sim = cosdis(word2vec(taxon_gt), word2vec(taxon_predicted))\n",
    "        cosine_sim.append(sim)\n",
    "        # print(taxon_gt, taxon_predicted, sim)\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        cosine_sim.append(0)\n",
    "        # print(taxon_gt, taxon_predicted,\"0\")\n",
    "\n",
    "# append similarity scores to the dataframe\n",
    "combined_df[\"Cosine_Similarity\"] = cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d8b3ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confidence_Threshold</th>\n",
       "      <th>Taxons_Predicted</th>\n",
       "      <th>Taxons_Accuracy_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.477477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.477477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.477477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.477477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.495238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.608108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.643478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Confidence_Threshold  Taxons_Predicted  Taxons_Accuracy_Predicted\n",
       "0                   0.0             106.0                   0.477477\n",
       "1                   0.1             106.0                   0.477477\n",
       "2                   0.2             106.0                   0.477477\n",
       "3                   0.3             106.0                   0.477477\n",
       "4                   0.4             104.0                   0.495238\n",
       "5                   0.5             100.0                   0.543478\n",
       "6                   0.6              90.0                   0.608108\n",
       "7                   0.7              74.0                   0.643478\n",
       "8                   0.8              56.0                   0.746667\n",
       "9                   0.9              28.0                   0.717949"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_taxon_prediction = pd.DataFrame(columns=[\"Confidence_Threshold\", \"Taxons_Predicted\", \"Taxons_Accuracy_Predicted\"])\n",
    "temp_df = pd.DataFrame()\n",
    "\n",
    "# generate list of similarity thresholds\n",
    "# sim_threshold = [0.9]\n",
    "sim_threshold =0.8\n",
    "\n",
    "# generate list of confidence thresholds\n",
    "confidence_threshold = np.arange(0, 1, 0.1)\n",
    "\n",
    "# compute prediction accuracy at each confidence threshold\n",
    "for conf_threshold in confidence_threshold:\n",
    "    \n",
    "    temp_df = combined_df[(combined_df[\"Confidence_Output\"] > conf_threshold)]\n",
    "    \n",
    "    acc_count = (temp_df[\"Cosine_Similarity\"] > sim_threshold).sum()\n",
    "\n",
    "    acc_val = acc_count/len(temp_df)\n",
    "\n",
    "    temp = [conf_threshold, acc_count, acc_val]\n",
    "    final_taxon_prediction.loc[len(final_taxon_prediction)] = temp\n",
    "\n",
    "display(final_taxon_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df36a9",
   "metadata": {},
   "source": [
    "1. We first obtain the taxon predictions with a confidence score for each taxon.\n",
    "2. We then compute cosine similarities of the predicted taxons with the ground truth taxons.\n",
    "3. We then, at each interval of the confidence threashold, compute number of taxons that have a high cosine similarity with the ground truth. The scores above are computed for a specific cosine similarity score \">0.8\". We need to perform this step because, the taxons are matched against entries from the `ncbi_taxonomy` database (as part of TaxoNERD) and, the predicted taxon might not exactly match the ground truth and we are accounting for this using cosine similarity.\n",
    "\n",
    "We can try to use the GBIF database to predict taxons and also experiment with different thresholds for the cosine similarity scores. But, in general, the chosen cosine similarity threshold offers an incremental performance upgrade compared to the last semester's work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ef4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1084cc30a0beff5f5a336ac1440c1980742df576b417f0ade42be5b6e50918a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
